"""
Layer 3 æ·±åº¦åˆ†æ CLI é€²å…¥é»ã€‚

ç”¨æ³•:
    # æŒ‡å®šè‚¡ç¥¨åˆ†æ
    uv run python -m scripts.analyzer.run_layer3 --tickers AAPL MSFT

    # å¾ Layer 1 ç¯©é¸çµæœè‡ªå‹•è¼‰å…¥é€šéçš„è‚¡ç¥¨
    uv run python -m scripts.analyzer.run_layer3 --from-layer1

    # å¼·åˆ¶é‡æ–°æŠ“å–ï¼Œå¿½ç•¥å¿«å–
    uv run python -m scripts.analyzer.run_layer3 --tickers AAPL --force-refresh

    # æŒ‡å®šè‚¡ç¥¨æ¸…å–®ç¯„åœï¼ˆåŒæ¥­æ¯”è¼ƒç”¨ï¼‰
    uv run python -m scripts.analyzer.run_layer3 --tickers AAPL --universe sp1500
"""

import argparse
import logging
import sys
from pathlib import Path

from scripts.analyzer.deep_data_fetcher import (
    fetch_deep_data,
    DeepDataCache,
    DeepAnalysisData,
)
from scripts.analyzer.peer_finder import build_peer_comparison
from scripts.analyzer.report_generator import generate_report
from scripts.scanner.results_store import (
    load_latest_results,
    save_deep_analysis,
)

# å ±å‘Šè¼¸å‡ºç›®éŒ„
REPORTS_DIR = Path("data/reports")

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
)
logger = logging.getLogger(__name__)

# å…¨åŸŸå¿«å–å¯¦ä¾‹
_cache = DeepDataCache()


def _load_layer1_passed_tickers() -> list[str]:
    """
    å¾æœ€æ–°çš„ Layer 1 ç¯©é¸çµæœä¸­è¼‰å…¥é€šéçš„è‚¡ç¥¨ä»£ç¢¼ã€‚

    å„ªå…ˆè¼‰å…¥é›™è»Œåˆ¶çµæœï¼Œå…¶æ¬¡è¼‰å…¥çµ•å°é–€æª»çµæœã€‚
    """
    # å…ˆå˜—è©¦é›™è»Œåˆ¶çµæœ
    data = load_latest_results(tag="layer1_dual")
    if data is None:
        data = load_latest_results(tag="layer1")

    if data is None:
        logger.error("æ‰¾ä¸åˆ° Layer 1 ç¯©é¸çµæœï¼Œè«‹å…ˆåŸ·è¡Œ Layer 1 ç¯©é¸")
        return []

    passed_tickers = []
    for r in data.get("results", []):
        if r.get("passed", False):
            passed_tickers.append(r["symbol"])

    logger.info(
        "å¾ Layer 1 çµæœè¼‰å…¥ %d æ”¯é€šéç¯©é¸çš„è‚¡ç¥¨ (å…± %d æ”¯)",
        len(passed_tickers), data.get("total_screened", 0),
    )
    return passed_tickers


def _analyze_single(
    symbol: str,
    universe: str = "sp500",
    peer_count: int = 5,
    use_cache: bool = True,
    ai_summary: bool = True,
    include_chart: bool = True,
) -> dict | None:
    """
    å°å–®ä¸€è‚¡ç¥¨åŸ·è¡Œå®Œæ•´æ·±åº¦åˆ†ææµç¨‹ã€‚

    æµç¨‹ï¼šæŠ“å–æ·±åº¦æ•¸æ“š â†’ åŒæ¥­æ¯”è¼ƒ â†’ ç”Ÿæˆå ±å‘Š â†’ æŒä¹…åŒ–ã€‚

    Returns:
        generate_report() çš„çµæœå­—å…¸ï¼Œæˆ– Noneï¼ˆå¤±æ•—æ™‚ï¼‰
    """
    # 1. æª¢æŸ¥å¿«å–
    if use_cache:
        cached = _cache.get(symbol)
        if cached is not None:
            logger.info("[å¿«å–å‘½ä¸­] %sï¼Œç›´æ¥ç”Ÿæˆå ±å‘Š", symbol)
            result = generate_report(
                cached,
                ai_summary=ai_summary,
                include_chart=include_chart,
                output_dir=REPORTS_DIR,
            )
            return result

    # 2. æŠ“å–æ·±åº¦æ•¸æ“š
    logger.info("[æŠ“å–ä¸­] %s æ·±åº¦æ•¸æ“š...", symbol)
    deep_data = fetch_deep_data(symbol)

    if not deep_data.company_name:
        logger.warning("[è·³é] %s: ç„¡æ³•å–å¾—åŸºç¤æ•¸æ“š", symbol)
        return None

    # 3. åŒæ¥­æ¯”è¼ƒ
    if deep_data.sector and deep_data.industry:
        logger.info("[åŒæ¥­æ¯”è¼ƒ] %s: %s > %s", symbol, deep_data.sector, deep_data.industry)
        try:
            import yfinance as yf
            target_info = yf.Ticker(symbol).info or {}
            peer_data = build_peer_comparison(
                symbol=symbol,
                sector=deep_data.sector,
                industry=deep_data.industry,
                target_info=target_info,
                universe=universe,
                peer_count=peer_count,
            )
            deep_data.peer_comparison = peer_data
        except Exception as e:
            logger.warning("[åŒæ¥­æ¯”è¼ƒå¤±æ•—] %s: %s", symbol, e)
    else:
        logger.warning("[è·³éåŒæ¥­æ¯”è¼ƒ] %s: ç¼ºå°‘ç”¢æ¥­è³‡è¨Š", symbol)

    # 4. å¿«å–å­˜å…¥
    if use_cache:
        _cache.put(deep_data)
        _cache.save()

    # 5. ç”Ÿæˆå ±å‘Š
    result = generate_report(
        deep_data,
        ai_summary=ai_summary,
        include_chart=include_chart,
        output_dir=REPORTS_DIR,
    )

    # 6. æŒä¹…åŒ–
    paths = save_deep_analysis(
        symbol=symbol,
        json_data=result["json_data"],
        markdown_report=result["markdown_report"],
    )
    logger.info("[å®Œæˆ] %s â†’ %s", symbol, paths["json_path"].name)

    return result


def _print_summary(results: list[dict]):
    """å°å‡ºæ‰€æœ‰åˆ†æçµæœçš„æ‘˜è¦è¡¨æ ¼ã€‚"""
    if not results:
        print("\nâš ï¸ æ²’æœ‰æˆåŠŸå®Œæˆåˆ†æçš„è‚¡ç¥¨ã€‚")
        return

    print("\n" + "=" * 80)
    print("ğŸ“Š Layer 3 æ·±åº¦åˆ†ææ‘˜è¦")
    print("=" * 80)

    header = f"{'ä»£ç¢¼':8s} | {'å…¬å¸åç¨±':20s} | {'ç¾åƒ¹':>10s} | {'ç›®æ¨™åƒ¹':>10s} | {'ä¸Šè¡Œç©ºé–“':>8s} | {'æ¨è–¦':8s} | {'å“è³ª':>5s}"
    print(header)
    print("-" * len(header))

    for r in results:
        s = r["summary"]
        sym = s.get("symbol", "")[:8]
        name = (s.get("company_name", "") or "")[:20]
        price = f"${s['current_price']:.2f}" if s.get("current_price") else "N/A"
        target = f"${s['target_price']:.2f}" if s.get("target_price") else "N/A"
        upside = f"{s['upside_pct']:+.1f}%" if s.get("upside_pct") is not None else "N/A"
        rec = (s.get("recommendation") or "N/A").upper()[:8]
        quality = f"{s.get('data_quality_score', 0) * 100:.0f}%"

        print(f"{sym:8s} | {name:20s} | {price:>10s} | {target:>10s} | {upside:>8s} | {rec:8s} | {quality:>5s}")

    print("=" * 80)


def main():
    parser = argparse.ArgumentParser(
        description="Layer 3 Deep Analysis â€” æ·±åº¦åˆ†æèˆ‡å ±å‘Šç”Ÿæˆ",
    )
    parser.add_argument(
        "--tickers", nargs="+",
        help="æŒ‡å®šè¦åˆ†æçš„è‚¡ç¥¨ä»£ç¢¼ï¼ˆç©ºæ ¼åˆ†éš”ï¼‰",
    )
    parser.add_argument(
        "--from-layer1", action="store_true", default=False,
        help="è‡ªå‹•è¼‰å…¥ Layer 1 ç¯©é¸é€šéçš„è‚¡ç¥¨",
    )
    parser.add_argument(
        "--universe",
        choices=["sp500", "sp400", "sp600", "sp1500"],
        default="sp500",
        help="åŒæ¥­æ¯”è¼ƒä½¿ç”¨çš„è‚¡ç¥¨æ¸…å–®ï¼ˆé è¨­: sp500ï¼‰",
    )
    parser.add_argument(
        "--peer-count", type=int, default=5,
        help="æ¯æ”¯è‚¡ç¥¨çš„åŒæ¥­æ¯”è¼ƒæ•¸é‡ï¼ˆé è¨­: 5ï¼‰",
    )
    parser.add_argument(
        "--force-refresh", action="store_true", default=False,
        help="å¼·åˆ¶é‡æ–°æŠ“å–æ‰€æœ‰è³‡æ–™ï¼Œå¿½ç•¥å¿«å–",
    )
    parser.add_argument(
        "--no-ai-summary", action="store_true", default=False,
        help="åœç”¨ AI ç™½è©±æ‘˜è¦ï¼ˆT0ï¼‰",
    )
    parser.add_argument(
        "--no-chart", action="store_true", default=False,
        help="åœç”¨åƒ¹æ ¼èµ°å‹¢åœ–",
    )
    args = parser.parse_args()

    # å–å¾—åˆ†æç›®æ¨™
    if args.tickers:
        tickers = [t.upper() for t in args.tickers]
    elif args.from_layer1:
        tickers = _load_layer1_passed_tickers()
        if not tickers:
            sys.exit(1)
    else:
        parser.error("è«‹æŒ‡å®š --tickers æˆ– --from-layer1")
        return

    use_cache = not args.force_refresh
    ai_summary = not args.no_ai_summary
    include_chart = not args.no_chart

    logger.info("=" * 60)
    logger.info("Layer 3 æ·±åº¦åˆ†æé–‹å§‹")
    logger.info("åˆ†æç›®æ¨™: %d æ”¯è‚¡ç¥¨: %s", len(tickers), tickers)
    logger.info("åŒæ¥­æ¯”è¼ƒç¯„åœ: %s, æ¯æ”¯ %d å€‹åŒæ¥­", args.universe, args.peer_count)
    logger.info("å¿«å–: %s", "å•Ÿç”¨" if use_cache else "åœç”¨ (--force-refresh)")
    logger.info("AI ç™½è©±æ‘˜è¦: %s", "å•Ÿç”¨" if ai_summary else "åœç”¨")
    logger.info("åƒ¹æ ¼èµ°å‹¢åœ–: %s", "å•Ÿç”¨" if include_chart else "åœç”¨")
    logger.info("=" * 60)

    # è¼‰å…¥å¿«å–
    if use_cache:
        _cache.load()

    # é€æ”¯åˆ†æ
    results = []
    for i, symbol in enumerate(tickers, 1):
        logger.info("[%d/%d] é–‹å§‹åˆ†æ %s...", i, len(tickers), symbol)
        try:
            result = _analyze_single(
                symbol=symbol,
                universe=args.universe,
                peer_count=args.peer_count,
                use_cache=use_cache,
                ai_summary=ai_summary,
                include_chart=include_chart,
            )
            if result:
                results.append(result)
        except Exception as e:
            logger.error("[å¤±æ•—] %s: %s", symbol, e)

    # å°å‡ºæ‘˜è¦
    _print_summary(results)

    logger.info(
        "åˆ†æå®Œæˆ: %d/%d æ”¯æˆåŠŸ", len(results), len(tickers),
    )


if __name__ == "__main__":
    main()
